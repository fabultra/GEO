#!/usr/bin/env python3
"""
Test sp√©cifique pour l'analyse s√©mantique profonde avec Claude 3.5 Sonnet
Teste les fonctionnalit√©s am√©lior√©es demand√©es dans la review request
"""
import sys
import os
import json
import requests
from datetime import datetime

sys.path.append('/app/backend')

from semantic_analyzer import SemanticAnalyzer
from query_generator_v2 import generate_queries_with_analysis

def test_claude_api():
    """Test if Claude API is working with the specified model"""
    print("ü§ñ TESTING CLAUDE API CONNECTIVITY")
    print("=" * 60)
    
    try:
        from anthropic import Anthropic
        
        api_key = os.environ.get('ANTHROPIC_API_KEY')
        if not api_key:
            print("‚ùå ANTHROPIC_API_KEY not found in environment")
            return False
        
        print(f"‚úÖ API Key found: {api_key[:20]}...")
        
        client = Anthropic(api_key=api_key)
        
        # Test with the model specified in the review request
        response = client.messages.create(
            model="claude-3-5-sonnet-20240620",
            max_tokens=100,
            messages=[
                {"role": "user", "content": "Test message. Respond with 'API Working' in JSON format: {\"status\": \"API Working\"}"}
            ]
        )
        
        response_text = response.content[0].text
        print(f"‚úÖ Claude API Response: {response_text}")
        
        if 'API Working' in response_text or 'working' in response_text.lower():
            print("‚úÖ Claude API is working correctly!")
            return True
        else:
            print("‚ö†Ô∏è  Claude API responded but format unexpected")
            return True
        
    except Exception as e:
        print(f"‚ùå Claude API test failed: {str(e)}")
        return False

def test_semantic_analysis():
    """Test semantic analysis with enhanced features for sekoia.ca"""
    
    # Enhanced sample crawl data for sekoia.ca (more realistic)
    sample_crawl_data = {
        'base_url': 'https://sekoia.ca',
        'pages_crawled': 5,
        'pages': [
            {
                'url': 'https://sekoia.ca',
                'title': 'SEKOIA - Cybers√©curit√© et Intelligence des Menaces | Protection Avanc√©e',
                'meta_description': 'SEKOIA d√©veloppe des solutions de cybers√©curit√© et d\'intelligence des menaces pour prot√©ger les entreprises contre les cyberattaques sophistiqu√©es.',
                'h1': ['SEKOIA', 'Cybers√©curit√© Avanc√©e', 'Protection des Entreprises'],
                'h2': ['Solutions de S√©curit√©', 'Intelligence des Menaces', 'Services SOC Manag√©s', 'Plateforme SOAR'],
                'h3': ['SOAR Platform', 'Threat Intelligence', 'SOC Services', 'Formation Cybers√©curit√©'],
                'paragraphs': [
                    'SEKOIA est une entreprise fran√ßaise leader sp√©cialis√©e dans la cybers√©curit√© et l\'intelligence des menaces avanc√©es. Nous d√©veloppons des solutions innovantes de s√©curit√© pour prot√©ger les entreprises contre les cyberattaques sophistiqu√©es et les menaces persistantes avanc√©es.',
                    'Notre plateforme SOAR (Security Orchestration, Automation and Response) r√©volutionnaire permet aux √©quipes de s√©curit√© d\'automatiser leurs processus de d√©tection, d\'investigation et de r√©ponse aux incidents de s√©curit√© en temps r√©el.',
                    'Nos services d\'intelligence des menaces de pointe fournissent des informations contextuelles critiques sur les acteurs malveillants, leurs techniques d\'attaque, et les indicateurs de compromission pour une protection proactive.',
                    'Nous proposons √©galement des services SOC (Security Operations Center) manag√©s complets pour les entreprises qui souhaitent externaliser leur surveillance de s√©curit√© 24/7 avec des experts certifi√©s.',
                    'Notre √©quipe d\'experts en cybers√©curit√©, compos√©e d\'analystes certifi√©s et de chercheurs en s√©curit√©, accompagne les organisations dans leur transformation digitale s√©curis√©e et leur mise en conformit√© r√©glementaire.',
                    'SEKOIA travaille avec des entreprises de toutes tailles, des PME innovantes aux grandes corporations multinationales, dans tous les secteurs d\'activit√© critiques incluant la finance, la sant√©, l\'√©nergie et les t√©l√©communications.',
                    'Nos solutions de cybers√©curit√© sont d√©ploy√©es dans plus de 50 pays √† travers le monde et prot√®gent des millions d\'utilisateurs contre les cybermenaces √©mergentes et les attaques zero-day.',
                    'La plateforme SEKOIA.IO int√®gre des capacit√©s avanc√©es d\'analyse comportementale, de machine learning et d\'intelligence artificielle pour d√©tecter les menaces sophistiqu√©es et les attaques furtives.',
                    'Nous offrons des programmes de formation sp√©cialis√©s en cybers√©curit√© pour sensibiliser les √©quipes IT aux bonnes pratiques de s√©curit√© et d√©velopper leurs comp√©tences en r√©ponse aux incidents.',
                    'Notre centre de recherche et d√©veloppement d√©veloppe en permanence de nouvelles techniques de d√©tection, d\'analyse des malwares et de threat hunting pour anticiper les menaces futures.',
                    'Les entreprises clientes b√©n√©ficient d\'un accompagnement personnalis√© pour √©valuer leur posture de s√©curit√©, identifier les vuln√©rabilit√©s critiques et mettre en place une strat√©gie de cybers√©curit√© robuste.',
                    'SEKOIA propose des services de conseil en cybers√©curit√©, d\'audit de s√©curit√©, de tests d\'intrusion et d\'√©valuation des risques pour renforcer la r√©silience des infrastructures critiques.'
                ],
                'json_ld': [],
                'word_count': 350
            },
            {
                'url': 'https://sekoia.ca/solutions',
                'title': 'Solutions de Cybers√©curit√© - SEKOIA',
                'meta_description': 'D√©couvrez nos solutions compl√®tes: plateforme SOAR, intelligence des menaces, SOC manag√©, formation cybers√©curit√©.',
                'h1': ['Solutions de Cybers√©curit√©'],
                'h2': ['Plateforme SOAR', 'Intelligence des Menaces', 'SOC Manag√©', 'Formation et Conseil'],
                'h3': ['Automatisation S√©curit√©', 'Threat Hunting', 'Monitoring 24/7', 'Certification S√©curit√©'],
                'paragraphs': [
                    'Notre plateforme SOAR automatise la d√©tection, l\'analyse et la r√©ponse aux incidents de s√©curit√© pour r√©duire les temps de r√©action et am√©liorer l\'efficacit√© des √©quipes SOC.',
                    'Les services d\'intelligence des menaces fournissent une visibilit√© en temps r√©el sur le paysage des menaces avec des indicateurs de compromission actualis√©s et des analyses contextuelles.',
                    'Le SOC manag√© offre une surveillance continue 24/7 avec des analystes experts qui monitent, d√©tectent et r√©pondent aux incidents de s√©curit√© pour le compte de nos clients.',
                    'Nos programmes de formation certifiants d√©veloppent les comp√©tences en cybers√©curit√© des √©quipes IT avec des modules pratiques sur la r√©ponse aux incidents et l\'analyse forensique.',
                    'Les services de conseil accompagnent les organisations dans l\'√©valuation de leur maturit√© s√©curit√©, la d√©finition de leur strat√©gie de cybers√©curit√© et la mise en conformit√© r√©glementaire.'
                ],
                'json_ld': [],
                'word_count': 180
            }
        ]
    }
    
    print("üß† Testing Semantic Analysis Module")
    print("=" * 50)
    
    # Test 1: Semantic Analysis
    analyzer = SemanticAnalyzer()
    semantic_results = analyzer.analyze_site(sample_crawl_data)
    
    print("‚úÖ Industry Classification:")
    industry_class = semantic_results.get('industry_classification', {})
    print(f"   - Primary Industry: {industry_class.get('primary_industry', 'unknown')}")
    print(f"   - Sub-industry: {industry_class.get('sub_industry', 'N/A')}")
    print(f"   - Company Type: {industry_class.get('company_type', 'unknown')}")
    print(f"   - Business Model: {industry_class.get('business_model', 'unknown')}")
    print(f"   - Positioning: {industry_class.get('positioning', 'N/A')}")
    print(f"   - Maturity: {industry_class.get('maturity', 'N/A')}")
    print(f"   - Geographic Scope: {industry_class.get('geographic_scope', 'N/A')}")
    print(f"   - Confidence: {industry_class.get('confidence', 0):.2f}")
    print(f"   - Reasoning: {industry_class.get('reasoning', 'N/A')}")
    
    print("\n‚úÖ Entities Extracted:")
    entities = semantic_results.get('entities', {})
    offerings = entities.get('offerings', [])
    print(f"   - Offerings: {len(offerings)} found")
    for i, offering in enumerate(offerings[:5]):
        if isinstance(offering, dict):
            print(f"     {i+1}. {offering.get('name', 'N/A')}")
            print(f"        Description: {offering.get('description', 'N/A')}")
            print(f"        Target Segment: {offering.get('target_segment', 'N/A')}")
            print(f"        Priority: {offering.get('priority', 'N/A')}")
        else:
            print(f"     {i+1}. {offering}")
    
    locations = entities.get('locations', [])
    print(f"   - Locations: {len(locations)} found")
    for loc in locations[:3]:
        print(f"     - {loc.get('city', 'N/A')}, {loc.get('region', 'N/A')}")
    
    problems = entities.get('problems_solved', [])
    print(f"   - Problems Solved: {len(problems)} found")
    for i, prob in enumerate(problems[:5]):
        if isinstance(prob, dict):
            print(f"     {i+1}. {prob.get('problem', 'N/A')}")
            print(f"        Category: {prob.get('category', 'N/A')}")
            print(f"        Severity: {prob.get('severity', 'N/A')}")
            print(f"        Solution Approach: {prob.get('solution_approach', 'N/A')}")
        else:
            print(f"     {i+1}. {prob}")
    
    # Test Topics (LDA)
    topics = semantic_results.get('topics', [])
    print(f"   - Topics (LDA): {len(topics)} found")
    for i, topic in enumerate(topics[:3]):
        if isinstance(topic, dict):
            print(f"     {i+1}. {topic.get('label', 'N/A')}")
            print(f"        Keywords: {topic.get('keywords', [])}")
            print(f"        Top Words Scores: {topic.get('top_words_scores', [])}")
        else:
            print(f"     {i+1}. {topic}")
    
    # Test 2: Query Generation
    print("\nüîç Testing Query Generation (100 queries)")
    print("=" * 50)
    
    query_results = generate_queries_with_analysis(sample_crawl_data, num_queries=100)
    
    queries = query_results.get('queries', [])
    breakdown = query_results.get('breakdown', {})
    
    print(f"‚úÖ Query Generation Results:")
    print(f"   - Total queries generated: {len(queries)}")
    print(f"   - Non-branded: {breakdown.get('non_branded', 0)}")
    print(f"   - Semi-branded: {breakdown.get('semi_branded', 0)}")
    print(f"   - Branded: {breakdown.get('branded', 0)}")
    
    # Calculate percentages
    total = len(queries)
    if total > 0:
        non_branded_pct = (breakdown.get('non_branded', 0) / total) * 100
        semi_branded_pct = (breakdown.get('semi_branded', 0) / total) * 100
        branded_pct = (breakdown.get('branded', 0) / total) * 100
        
        print(f"   - Distribution: {non_branded_pct:.1f}% / {semi_branded_pct:.1f}% / {branded_pct:.1f}%")
        print(f"   - Target: 80% / 15% / 5%")
        
        # Check if distribution is correct
        if non_branded_pct >= 70 and total >= 90:
            print("   - ‚úÖ Distribution is acceptable")
        else:
            print("   - ‚ö†Ô∏è  Distribution needs improvement")
    
    print(f"\nüìù Sample Queries (first 10):")
    for i, query in enumerate(queries[:10]):
        print(f"   {i+1}. {query}")
    
    # Test 3: Validation
    print(f"\nüîç Validation Results:")
    print("=" * 50)
    
    # Check ENHANCED FEATURES as requested in review
    print("üîç ENHANCED FEATURES VALIDATION (Review Request):")
    enhanced_features_present = True
    missing_features = []
    
    # Check industry classification enhanced fields
    required_industry_fields = ['sub_industry', 'positioning', 'maturity', 'geographic_scope', 'reasoning']
    for field in required_industry_fields:
        if field not in industry_class:
            enhanced_features_present = False
            missing_features.append(f"industry_classification.{field}")
    
    # Check offerings enhanced fields (12 items required)
    if offerings:
        required_offering_fields = ['description', 'target_segment', 'priority']
        for field in required_offering_fields:
            if isinstance(offerings[0], dict) and field not in offerings[0]:
                enhanced_features_present = False
                missing_features.append(f"offerings.{field}")
        
        if len(offerings) < 12:
            print(f"   ‚ö†Ô∏è  Only {len(offerings)} offerings found (target: 12)")
    
    # Check problems_solved enhanced fields (15 items required)
    if problems:
        required_problem_fields = ['category', 'severity', 'solution_approach']
        for field in required_problem_fields:
            if isinstance(problems[0], dict) and field not in problems[0]:
                enhanced_features_present = False
                missing_features.append(f"problems_solved.{field}")
        
        if len(problems) < 15:
            print(f"   ‚ö†Ô∏è  Only {len(problems)} problems found (target: 15)")
    
    # Check LDA topics enhanced fields
    topics = semantic_results.get('topics', [])
    if topics:
        required_topic_fields = ['keywords', 'top_words_scores']
        for field in required_topic_fields:
            if isinstance(topics[0], dict) and field not in topics[0]:
                enhanced_features_present = False
                missing_features.append(f"topics.{field}")
    
    if enhanced_features_present:
        print("   ‚úÖ ALL enhanced features are present!")
    else:
        print("   ‚ùå Missing enhanced features:")
        for feature in missing_features:
            print(f"     - {feature}")
    
    # Check if semantic analysis has required fields
    required_fields = ['industry_classification', 'entities', 'topics']
    missing_fields = []
    
    for field in required_fields:
        if field not in semantic_results:
            missing_fields.append(field)
    
    if not missing_fields:
        print("‚úÖ All required semantic analysis fields present")
    else:
        print(f"‚ùå Missing fields: {missing_fields}")
    
    # Check if query breakdown has required fields
    required_breakdown_fields = ['non_branded', 'semi_branded', 'branded', 'total']
    missing_breakdown = []
    
    for field in required_breakdown_fields:
        if field not in breakdown:
            missing_breakdown.append(field)
    
    if not missing_breakdown:
        print("‚úÖ All required query breakdown fields present")
    else:
        print(f"‚ùå Missing breakdown fields: {missing_breakdown}")
    
    # Overall assessment
    print(f"\nüìä Overall Assessment:")
    print("=" * 50)
    
    success_count = 0
    total_tests = 6
    
    # Test 1: Industry detected
    if industry_class.get('primary_industry', 'unknown') != 'unknown':
        print("‚úÖ Industry detection: PASS")
        success_count += 1
    else:
        print("‚ùå Industry detection: FAIL")
    
    # Test 2: Offerings extracted
    if len(offerings) > 0:
        print("‚úÖ Offerings extraction: PASS")
        success_count += 1
    else:
        print("‚ùå Offerings extraction: FAIL")
    
    # Test 3: Queries generated
    if len(queries) >= 50:  # At least 50 queries
        print("‚úÖ Query generation: PASS")
        success_count += 1
    else:
        print("‚ùå Query generation: FAIL")
    
    # Test 4: Non-branded queries
    if breakdown.get('non_branded', 0) > 0:
        print("‚úÖ Non-branded queries: PASS")
        success_count += 1
    else:
        print("‚ùå Non-branded queries: FAIL")
    
    # Test 5: Semantic analysis structure
    if not missing_fields:
        print("‚úÖ Semantic analysis structure: PASS")
        success_count += 1
    else:
        print("‚ùå Semantic analysis structure: FAIL")
    
    # Test 6: Query breakdown structure
    if not missing_breakdown:
        print("‚úÖ Query breakdown structure: PASS")
        success_count += 1
    else:
        print("‚ùå Query breakdown structure: FAIL")
    
    print(f"\nüéØ Final Score: {success_count}/{total_tests} tests passed ({(success_count/total_tests)*100:.1f}%)")
    
    if success_count == total_tests:
        print("üéâ ALL TESTS PASSED - Semantic Analysis Module is working correctly!")
        return True
    elif success_count >= 4:
        print("‚ö†Ô∏è  MOSTLY WORKING - Some minor issues detected")
        return True
    else:
        print("‚ùå MAJOR ISSUES - Semantic Analysis Module needs fixes")
        return False

if __name__ == "__main__":
    success = test_semantic_analysis()
    sys.exit(0 if success else 1)