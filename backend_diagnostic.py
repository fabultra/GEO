#!/usr/bin/env python3
"""
Diagnostic rapide du backend GEO SaaS bas√© sur les fichiers existants
"""
import json
import logging
import os
import sys
from datetime import datetime
import subprocess

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_existing_reports():
    """Analyser les rapports existants sur le disque"""
    logger.info("üîç Analyse des rapports existants")
    
    dashboards_dir = "/app/backend/dashboards"
    reports_dir = "/app/backend/reports"
    
    results = {
        'dashboards_found': 0,
        'reports_found': 0,
        'report_ids': [],
        'dashboard_files': [],
        'report_files': []
    }
    
    # Analyser les dashboards
    if os.path.exists(dashboards_dir):
        dashboard_files = [f for f in os.listdir(dashboards_dir) if f.endswith('.html')]
        results['dashboards_found'] = len(dashboard_files)
        results['dashboard_files'] = dashboard_files[:5]  # Premiers 5
        
        # Extraire les IDs de rapport
        for file in dashboard_files:
            if '_dashboard.html' in file:
                report_id = file.replace('_dashboard.html', '')
                if report_id not in results['report_ids']:
                    results['report_ids'].append(report_id)
    
    # Analyser les rapports Word
    if os.path.exists(reports_dir):
        report_files = [f for f in os.listdir(reports_dir) if f.endswith('.docx')]
        results['reports_found'] = len(report_files)
        results['report_files'] = report_files[:5]  # Premiers 5
    
    logger.info(f"üìä Dashboards trouv√©s: {results['dashboards_found']}")
    logger.info(f"üìä Rapports Word trouv√©s: {results['reports_found']}")
    logger.info(f"üìä IDs de rapport identifi√©s: {len(results['report_ids'])}")
    
    return results

def analyze_backend_logs():
    """Analyser les logs backend pour identifier les probl√®mes"""
    logger.info("üîç Analyse des logs backend")
    
    log_files = [
        '/var/log/supervisor/backend.err.log',
        '/var/log/supervisor/backend.out.log'
    ]
    
    issues = {
        'critical_errors': [],
        'api_errors': [],
        'timeout_errors': [],
        'model_errors': [],
        'recent_activity': []
    }
    
    for log_file in log_files:
        try:
            result = subprocess.run(['tail', '-n', '100', log_file], 
                                  capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0:
                lines = result.stdout.split('\n')
                
                for line in lines:
                    if not line.strip():
                        continue
                    
                    # Erreurs critiques
                    if any(keyword in line for keyword in ['CRITICAL', 'Exception', 'Traceback']):
                        issues['critical_errors'].append(line.strip())
                    
                    # Erreurs API
                    elif any(keyword in line for keyword in ['404', '500', 'HTTP', 'API']):
                        issues['api_errors'].append(line.strip())
                    
                    # Erreurs de timeout
                    elif any(keyword in line for keyword in ['timeout', 'Timeout', 'timed out']):
                        issues['timeout_errors'].append(line.strip())
                    
                    # Erreurs de mod√®le
                    elif any(keyword in line for keyword in ['model not found', 'models/', 'sequence item']):
                        issues['model_errors'].append(line.strip())
                    
                    # Activit√© r√©cente
                    elif any(keyword in line for keyword in ['INFO', 'Testing query', 'Analysis']):
                        issues['recent_activity'].append(line.strip())
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de lire {log_file}: {e}")
    
    # R√©sum√© des probl√®mes
    logger.info(f"üö® Erreurs critiques: {len(issues['critical_errors'])}")
    logger.info(f"üåê Erreurs API: {len(issues['api_errors'])}")
    logger.info(f"‚è∞ Erreurs timeout: {len(issues['timeout_errors'])}")
    logger.info(f"ü§ñ Erreurs mod√®le: {len(issues['model_errors'])}")
    logger.info(f"üìã Activit√© r√©cente: {len(issues['recent_activity'])}")
    
    return issues

def check_api_models():
    """V√©rifier les mod√®les API configur√©s"""
    logger.info("üîç V√©rification des mod√®les API")
    
    env_file = "/app/backend/.env"
    api_keys = {}
    
    try:
        with open(env_file, 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    if 'API_KEY' in key:
                        api_keys[key] = value.replace('"', '')[:20] + "..." if len(value) > 20 else value
    except Exception as e:
        logger.error(f"‚ùå Impossible de lire {env_file}: {e}")
        return {}
    
    logger.info("üîë Cl√©s API configur√©es:")
    for key, value in api_keys.items():
        logger.info(f"  ‚Ä¢ {key}: {value}")
    
    return api_keys

def analyze_visibility_data():
    """Analyser les donn√©es de visibilit√© existantes"""
    logger.info("üîç Analyse des donn√©es de visibilit√©")
    
    dashboards_dir = "/app/backend/dashboards"
    visibility_files = []
    
    if os.path.exists(dashboards_dir):
        visibility_files = [f for f in os.listdir(dashboards_dir) if 'visibility_dashboard_data.json' in f]
    
    if not visibility_files:
        logger.warning("‚ö†Ô∏è Aucun fichier de donn√©es de visibilit√© trouv√©")
        return {}
    
    # Analyser le premier fichier trouv√©
    try:
        with open(os.path.join(dashboards_dir, visibility_files[0]), 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        summary = data.get('summary', {})
        queries = data.get('queries', [])
        
        logger.info(f"üìä Visibilit√© globale: {summary.get('global_visibility', 0):.1%}")
        logger.info(f"üìä Requ√™tes test√©es: {len(queries)}")
        logger.info(f"üìä Plateformes: {list(summary.get('by_platform', {}).keys())}")
        
        # Analyser les erreurs dans les requ√™tes
        platform_errors = {}
        for query in queries[:10]:  # Premiers 10
            for platform, platform_data in query.get('platforms', {}).items():
                if platform_data.get('error'):
                    if platform not in platform_errors:
                        platform_errors[platform] = 0
                    platform_errors[platform] += 1
        
        if platform_errors:
            logger.warning("‚ö†Ô∏è Erreurs par plateforme:")
            for platform, count in platform_errors.items():
                logger.warning(f"  ‚Ä¢ {platform}: {count} erreurs")
        
        return {
            'visibility_files_found': len(visibility_files),
            'global_visibility': summary.get('global_visibility', 0),
            'queries_tested': len(queries),
            'platform_errors': platform_errors
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur analyse visibilit√©: {e}")
        return {}

def check_service_status():
    """V√©rifier le statut des services"""
    logger.info("üîç V√©rification du statut des services")
    
    try:
        result = subprocess.run(['sudo', 'supervisorctl', 'status'], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            services = {}
            for line in result.stdout.split('\n'):
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 2:
                        service_name = parts[0]
                        status = parts[1]
                        services[service_name] = status
            
            logger.info("üîß Statut des services:")
            for service, status in services.items():
                status_icon = "‚úÖ" if status == "RUNNING" else "‚ùå"
                logger.info(f"  {status_icon} {service}: {status}")
            
            return services
        else:
            logger.error("‚ùå Impossible de v√©rifier le statut des services")
            return {}
    
    except Exception as e:
        logger.error(f"‚ùå Erreur v√©rification services: {e}")
        return {}

def generate_diagnostic_report():
    """G√©n√©rer le rapport de diagnostic complet"""
    logger.info("üöÄ DIAGNOSTIC BACKEND GEO SAAS")
    logger.info("="*60)
    
    diagnostic = {
        'timestamp': datetime.now().isoformat(),
        'services': {},
        'reports': {},
        'logs': {},
        'api_keys': {},
        'visibility': {},
        'issues_found': [],
        'recommendations': []
    }
    
    # 1. V√©rifier les services
    diagnostic['services'] = check_service_status()
    
    # 2. Analyser les rapports existants
    diagnostic['reports'] = analyze_existing_reports()
    
    # 3. Analyser les logs
    diagnostic['logs'] = analyze_backend_logs()
    
    # 4. V√©rifier les cl√©s API
    diagnostic['api_keys'] = check_api_models()
    
    # 5. Analyser les donn√©es de visibilit√©
    diagnostic['visibility'] = analyze_visibility_data()
    
    # Identifier les probl√®mes
    issues = []
    recommendations = []
    
    # Probl√®mes de service
    if diagnostic['services']:
        non_running = [s for s, status in diagnostic['services'].items() if status != 'RUNNING']
        if non_running:
            issues.append(f"Services non actifs: {', '.join(non_running)}")
            recommendations.append("Red√©marrer les services non actifs avec supervisorctl")
    
    # Probl√®mes d'API
    if diagnostic['logs']['model_errors']:
        issues.append(f"Erreurs de mod√®le API: {len(diagnostic['logs']['model_errors'])} occurrences")
        recommendations.append("V√©rifier les mod√®les Gemini et Claude configur√©s")
    
    if diagnostic['logs']['api_errors']:
        issues.append(f"Erreurs API: {len(diagnostic['logs']['api_errors'])} occurrences")
        recommendations.append("V√©rifier les cl√©s API et quotas")
    
    # Probl√®mes de performance
    if diagnostic['logs']['timeout_errors']:
        issues.append(f"Erreurs de timeout: {len(diagnostic['logs']['timeout_errors'])} occurrences")
        recommendations.append("Optimiser les timeouts et la performance")
    
    # Probl√®mes de visibilit√©
    if diagnostic['visibility'].get('platform_errors'):
        total_errors = sum(diagnostic['visibility']['platform_errors'].values())
        issues.append(f"Erreurs de plateforme de visibilit√©: {total_errors} total")
        recommendations.append("Corriger les erreurs d'API des plateformes de visibilit√©")
    
    diagnostic['issues_found'] = issues
    diagnostic['recommendations'] = recommendations
    
    # Rapport final
    logger.info("\nüìã R√âSUM√â DU DIAGNOSTIC")
    logger.info("="*40)
    
    logger.info(f"üîß Services actifs: {sum(1 for s in diagnostic['services'].values() if s == 'RUNNING')}/{len(diagnostic['services'])}")
    logger.info(f"üìä Rapports g√©n√©r√©s: {diagnostic['reports']['dashboards_found']} dashboards, {diagnostic['reports']['reports_found']} DOCX")
    logger.info(f"üîë Cl√©s API configur√©es: {len(diagnostic['api_keys'])}")
    logger.info(f"üëÅÔ∏è Visibilit√© globale: {diagnostic['visibility'].get('global_visibility', 0):.1%}")
    
    if issues:
        logger.info(f"\nüö® PROBL√àMES IDENTIFI√âS ({len(issues)}):")
        for i, issue in enumerate(issues, 1):
            logger.info(f"  {i}. {issue}")
    
    if recommendations:
        logger.info(f"\nüí° RECOMMANDATIONS ({len(recommendations)}):")
        for i, rec in enumerate(recommendations, 1):
            logger.info(f"  {i}. {rec}")
    
    # Sauvegarder le diagnostic
    with open('/app/backend_diagnostic_report.json', 'w', encoding='utf-8') as f:
        json.dump(diagnostic, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nüíæ Diagnostic sauvegard√©: /app/backend_diagnostic_report.json")
    
    # Score global
    total_checks = 5  # services, reports, api_keys, visibility, logs
    passed_checks = 0
    
    if diagnostic['services'] and all(s == 'RUNNING' for s in diagnostic['services'].values()):
        passed_checks += 1
    
    if diagnostic['reports']['dashboards_found'] > 0:
        passed_checks += 1
    
    if len(diagnostic['api_keys']) >= 3:  # Au moins 3 cl√©s API
        passed_checks += 1
    
    if diagnostic['visibility'].get('queries_tested', 0) > 0:
        passed_checks += 1
    
    if len(diagnostic['logs']['critical_errors']) == 0:
        passed_checks += 1
    
    score = (passed_checks / total_checks) * 100
    logger.info(f"\nüìä SCORE GLOBAL: {passed_checks}/{total_checks} ({score:.1f}%)")
    
    if score >= 80:
        logger.info("üéâ BACKEND EN BON √âTAT")
        return 0
    elif score >= 60:
        logger.info("‚ö†Ô∏è BACKEND FONCTIONNEL AVEC PROBL√àMES MINEURS")
        return 0
    else:
        logger.error("‚ùå BACKEND AVEC PROBL√àMES CRITIQUES")
        return 1

def main():
    return generate_diagnostic_report()

if __name__ == "__main__":
    sys.exit(main())