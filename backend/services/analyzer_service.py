"""
Service d'Analyse S√©mantique avec Claude
Analyse les sites web selon les 8 crit√®res GEO avec cache int√©gr√©
"""
import os
import json
import logging
import asyncio
import re
from typing import Dict, Any, Optional
from anthropic import AsyncAnthropic

logger = logging.getLogger(__name__)


class AnalyzerService:
    """Service pour l'analyse s√©mantique avec Claude"""
    
    def __init__(self):
        """Initialise le service avec la cl√© API"""
        self.api_key = os.environ.get('ANTHROPIC_API_KEY', os.environ.get('EMERGENT_LLM_KEY'))
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY ou EMERGENT_LLM_KEY requis")
        
        self.model = "claude-sonnet-4-5-20250929"
        self.max_tokens = 8192
        self.temperature = 0  # D√©terministe
        self.max_pages_to_analyze = 8
    
    async def analyze_with_claude(
        self, 
        crawl_data: Dict[str, Any], 
        visibility_data: Optional[Dict[str, Any]] = None,
        retry_count: int = 3,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyse un site avec Claude selon les 8 crit√®res GEO
        
        Args:
            crawl_data: Donn√©es du crawling (pages, contenu)
            visibility_data: R√©sultats des tests de visibilit√© IA (optionnel)
            retry_count: Nombre de tentatives en cas d'√©chec
            use_cache: Utiliser le cache (d√©faut: True)
            
        Returns:
            Dict contenant scores, observations, recommendations, quick_wins
        """
        
        # ============ CACHE CHECK ============
        cached_result = None
        cache_key = None
        
        if use_cache:
            try:
                cached_result, cache_key = await self._check_cache(crawl_data, visibility_data)
                if cached_result:
                    logger.info("‚úÖ CACHE HIT - saved ~$0.50 API cost")
                    return cached_result
                logger.info("üí∞ CACHE MISS - calling Claude...")
            except Exception as e:
                logger.debug(f"Cache check failed: {e}")
        # =====================================
        
        # Pr√©parer les donn√©es pour Claude
        pages_summary = self._prepare_pages_summary(crawl_data)
        analysis_prompt = self._build_analysis_prompt(crawl_data, pages_summary, visibility_data)
        
        # Appeler Claude avec retry
        response_text = await self._call_claude_with_retry(analysis_prompt, retry_count)
        
        # Parser la r√©ponse JSON
        analysis_result = await self._parse_claude_response(response_text)
        
        # Sauvegarder en cache si activ√©
        if use_cache and cache_key:
            try:
                from services.cache_service import cache_service
                cache_service.set(cache_key, analysis_result)
                logger.info("üíæ R√©sultat sauvegard√© en cache")
            except Exception as e:
                logger.debug(f"Cache save failed: {e}")
        
        return analysis_result
    
    async def _check_cache(
        self, 
        crawl_data: Dict[str, Any], 
        visibility_data: Optional[Dict[str, Any]]
    ) -> tuple[Optional[Dict], Optional[str]]:
        """V√©rifie si le r√©sultat est en cache"""
        try:
            from services.cache_service import cache_service
            import hashlib
            
            cache_key_data = {
                'base_url': crawl_data.get('base_url', ''),
                'pages_count': len(crawl_data.get('pages', [])),
                'vis_score': visibility_data.get('overall_visibility', 0) if visibility_data else 0,
                'v': '3'
            }
            cache_key = f"claude_v3_{hashlib.md5(json.dumps(cache_key_data, sort_keys=True).encode()).hexdigest()}"
            
            cached = cache_service.get(cache_key, max_age_hours=168)  # 7 jours
            return cached, cache_key
        except Exception as e:
            logger.debug(f"Cache check error: {e}")
            return None, None
    
    def _prepare_pages_summary(self, crawl_data: Dict[str, Any]) -> list:
        """Pr√©pare un r√©sum√© des pages pour Claude"""
        pages_summary = []
        
        for page in crawl_data['pages'][:self.max_pages_to_analyze]:
            pages_summary.append({
                'url': page['url'],
                'title': page['title'],
                'h1': page['h1'][:3],  # Limiter √† 3 H1
                'h2': page['h2'][:5],  # Limiter √† 5 H2
                'content_preview': ' '.join(page['paragraphs'][:2])[:400],
                'has_json_ld': len(page['json_ld']) > 0,
                'word_count': page['word_count']
            })
        
        return pages_summary
    
    def _build_analysis_prompt(
        self, 
        crawl_data: Dict[str, Any], 
        pages_summary: list,
        visibility_data: Optional[Dict[str, Any]]
    ) -> str:
        """Construit le prompt d'analyse pour Claude"""
        
        prompt = f"""
VOUS √äTES UN EXPERT GEO - ANALYSE RIGOUREUSE REQUISE

IMPORTANT: R√©pondez UNIQUEMENT en JSON valide. N'ajoutez AUCUN texte avant ou apr√®s le JSON.
Les descriptions doivent √™tre sur UNE SEULE ligne (pas de sauts de ligne).
√âchappez les guillemets dans les textes avec \\"

Analysez ce site web selon 8 crit√®res GEO avec notation 0-10 JUSTIFI√âE.

GRILLES DE SCORING (0-10):
‚Ä¢ Structure: 9-10=TL;DR partout + r√©ponses directes | 7-8=Bonne structure | 5-6=Structure basique | 3-4=Faible | 0-2=Aucune structure GEO
‚Ä¢ Densit√© Info: 9-10=Stats abondantes + donn√©es originales | 7-8=Bonnes stats | 5-6=Quelques stats | 3-4=Peu de donn√©es | 0-2=Aucune stat/donn√©e factuelle
‚Ä¢ Lisibilit√© Machine: 9-10=Schema complet + JSON-LD | 7-8=Schema principal | 5-6=Schema basique | 3-4=Schema incomplet | 0-2=Aucun schema
‚Ä¢ E-E-A-T: 9-10=Auteurs experts identifi√©s + certifications | 7-8=Bons auteurs | 5-6=Org cr√©dible, auteurs anonymes | 3-4=Faible E-E-A-T | 0-2=Aucun E-E-A-T
‚Ä¢ √âducatif: 9-10=50+ guides + FAQ + glossaires | 7-8=20-50 guides | 5-6=10-20 articles | 3-4=<10 articles | 0-2=Aucun contenu √©ducatif, 100% marketing
‚Ä¢ Th√©matique: 9-10=5+ hubs avec satellites | 7-8=3-5 hubs | 5-6=D√©but clustering | 3-4=Pas de silos | 0-2=Aucune organisation
‚Ä¢ Optimisation IA: 9-10=Format optimal + r√©ponses rapides | 7-8=Bon format | 5-6=Format acceptable | 3-4=Peu adapt√© IA | 0-2=Format anti-IA (marketing lourd)
‚Ä¢ Visibilit√©: 9-10=Tr√®s visible dans IA | 7-8=Visible | 5-6=Occasionnelle | 3-4=Tr√®s faible | 0-2=Invisible dans toutes IA

SITE ANALYS√â: {crawl_data['base_url']} | Pages: {crawl_data['pages_crawled']}

CONTENU:
{json.dumps(pages_summary, ensure_ascii=False, indent=2)}

DONN√âES DE VISIBILIT√â IA:
{json.dumps(visibility_data, ensure_ascii=False, indent=2) if visibility_data else "Aucune donn√©e de visibilit√© disponible"}

INSTRUCTIONS:
Pour CHAQUE crit√®re: score 0-10 justifi√© + probl√®mes sp√©cifiques + exemples concrets du site

IMPORTANT pour Crit√®res 7 & 8:
- Utilisez les VRAIES donn√©es de visibilit√© ci-dessus
- Crit√®re 7 (aiOptimization): Basez le score sur platform_scores
- Crit√®re 8 (visibility): Basez le score sur overall_visibility
- Convertissez les % en scores 0-10 (ex: 40% = 4.0/10)

JSON REQUIS (RESPECTEZ CE FORMAT EXACTEMENT):
{{
  "scores": {{"structure": 7.5, "infoDensity": 3.0, "readability": 5.0, "eeat": 6.0, "educational": 2.0, "thematic": 4.5, "aiOptimization": 3.5, "visibility": 2.5, "global_score": 4.25}},
  "detailed_observations": {{
    "structure": {{
      "score_justification": "Justification courte et precise du score",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2", "Probleme 3"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "infoDensity": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "readability": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "eeat": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "educational": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "thematic": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "aiOptimization": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }},
    "visibility": {{
      "score_justification": "Justification courte",
      "positive_points": ["Point fort 1", "Point fort 2"],
      "specific_problems": ["Probleme 1", "Probleme 2"],
      "missing_elements": ["Element manquant 1", "Element manquant 2"]
    }}
  }},
  "recommendations": [
    {{"title": "Ajouter des FAQ structurees", "criterion": "educational", "impact": "high", "effort": "medium", "priority": 1, "description": "Creer une section FAQ avec 20 questions sur une ligne", "example": "Schema FAQPage JSON-LD"}},
    {{"title": "Optimiser meta descriptions", "criterion": "readability", "impact": "high", "effort": "low", "priority": 2, "description": "Recrire toutes les meta en mode factuel sous 120 caracteres", "example": "Meta actuelle vs meta optimisee"}}
  ],
  "quick_wins": [
    {{"title": "Ajouter Schema Organization", "impact": "Visibilite immediate dans IA", "time_required": "1 heure", "description": "Implementer JSON-LD Organization sur page accueil"}},
    {{"title": "Creer section TL;DR", "impact": "Meilleur taux extraction IA", "time_required": "2 heures", "description": "Ajouter resume 40-60 mots debut de chaque page pilier"}}
  ],
  "analysis": {{"strengths": ["Force 1 detaillee"], "weaknesses": ["Faiblesse 1 detaillee"], "opportunities": ["Opportunite 1 avec potentiel"]}},
  "executive_summary": {{"global_assessment": "Evaluation en 2 phrases sans saut de ligne", "critical_issues": ["Probleme critique 1"], "key_opportunities": ["Opportunite majeure 1"], "estimated_visibility_loss": "60-70%", "recommended_investment": "Phase 1: 15-20k budget sur 3 mois"}},
  "roi_estimation": {{"current_situation": "Situation actuelle en une phrase", "potential_improvement": "Amelioration potentielle en une phrase", "timeline": "6-12 mois pour resultats"}}
}}

RAPPEL CRITIQUE:
- JSON valide UNIQUEMENT (pas de texte avant/apres)
- Descriptions sur UNE seule ligne
- **OBLIGATOIRE: Exactement 20 recommendations** (pas moins!)
- **OBLIGATOIRE: Exactement 8 quick_wins** (pas moins!)
- Observations detaillees pour LES 8 criteres
- Guillemets echappes avec \\"
- Chaque recommendation doit etre CONCRETE et ACTIONNABLE

IMPORTANT: Remplissez detailed_observations pour CHAQUE critere: structure, infoDensity, readability, eeat, educational, thematic, aiOptimization, visibility

VOUS DEVEZ G√âN√âRER 20 RECOMMENDATIONS VARI√âES COUVRANT:
- Structure et format (3-4 recs)
- Contenu et densit√© info (3-4 recs)
- Schema et donn√©es structur√©es (3-4 recs)
- E-E-A-T et cr√©dibilit√© (2-3 recs)
- Contenu √©ducatif (2-3 recs)
- Organisation th√©matique (2-3 recs)
- Optimisation IA (2-3 recs)
"""
        return prompt
    
    async def _call_claude_with_retry(self, prompt: str, retry_count: int) -> str:
        """Appelle Claude avec retry automatique en cas d'√©chec"""
        last_error = None
        response_text = None
        
        for attempt in range(retry_count):
            try:
                client = AsyncAnthropic(api_key=self.api_key)
                
                response = await client.messages.create(
                    model=self.model,
                    max_tokens=self.max_tokens,
                    temperature=self.temperature,
                    system="Vous √™tes un expert en GEO. R√©pondez uniquement en JSON valide.",
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                
                response_text = response.content[0].text
                logger.info("R√©ponse re√ßue de Claude")
                break  # Succ√®s
                
            except Exception as e:
                last_error = e
                logger.warning(f"Tentative {attempt + 1}/{retry_count} √©chou√©e: {str(e)}")
                
                if attempt < retry_count - 1:
                    wait_time = 2 ** attempt  # Backoff exponentiel: 1s, 2s, 4s
                    logger.info(f"Attente de {wait_time}s avant retry...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"Toutes les tentatives ont √©chou√©: {str(last_error)}")
                    raise last_error
        
        if not response_text:
            raise ValueError("Aucune r√©ponse re√ßue de Claude")
        
        return response_text
    
    async def _parse_claude_response(self, response_text: str) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de Claude avec nettoyage robuste"""
        
        # Nettoyer la r√©ponse
        response_text = response_text.strip()
        
        # Enlever les markdown code blocks
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0]
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0]
        
        response_text = response_text.strip()
        
        # Tentative 1: Parsing direct
        try:
            analysis_result = json.loads(response_text)
            
            if 'scores' not in analysis_result or 'recommendations' not in analysis_result:
                raise ValueError("Champs essentiels manquants")
            
            return analysis_result
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"Premi√®re tentative de parsing √©chou√©e: {str(e)}")
            
            # Tentative 2: Nettoyer les sauts de ligne dans les strings
            response_text = re.sub(
                r'(?<=: ")(.*?)(?="[,\}])', 
                lambda m: m.group(0).replace('\n', ' '), 
                response_text, 
                flags=re.DOTALL
            )
            
            try:
                analysis_result = json.loads(response_text)
                if 'scores' in analysis_result and 'recommendations' in analysis_result:
                    return analysis_result
            except Exception:
                pass
            
            # Tentative 3: Extraction manuelle des scores + g√©n√©ration recommendations
            logger.error("Impossible de parser le JSON complet. Extraction manuelle...")
            return await self._fallback_parse(response_text)
    
    async def _fallback_parse(self, response_text: str) -> Dict[str, Any]:
        """Parsing de secours quand le JSON est invalide"""
        
        # Extraire les scores
        scores_match = re.search(r'"scores":\s*\{([^}]+)\}', response_text)
        
        if scores_match:
            scores_text = '{' + scores_match.group(1) + '}'
            try:
                scores = json.loads(scores_text)
                logger.info("Scores extraits avec succ√®s")
                
                # G√©n√©rer les recommendations s√©par√©ment
                logger.info("G√©n√©ration s√©par√©e des recommendations...")
                recommendations = await self._generate_recommendations_fallback(scores)
                
                return {
                    'scores': scores,
                    'recommendations': recommendations,
                    'quick_wins': [],  # Sera rempli par le fallback
                    'analysis': {'strengths': [], 'weaknesses': [], 'opportunities': []},
                    'detailed_observations': {},
                    'executive_summary': {
                        'global_assessment': 'Analyse partielle g√©n√©r√©e',
                        'critical_issues': [],
                        'key_opportunities': []
                    }
                }
            except Exception as e:
                logger.error(f"√âchec extraction scores: {e}")
        
        # Dernier recours: scores par d√©faut
        logger.error("Utilisation des scores par d√©faut")
        return {
            'scores': {
                'structure': 5.0,
                'infoDensity': 5.0,
                'readability': 5.0,
                'eeat': 5.0,
                'educational': 5.0,
                'thematic': 5.0,
                'aiOptimization': 5.0,
                'visibility': 5.0,
                'global_score': 5.0
            },
            'recommendations': [],
            'quick_wins': [],
            'analysis': {'strengths': [], 'weaknesses': [], 'opportunities': []},
            'detailed_observations': {},
            'executive_summary': {
                'global_assessment': 'Erreur de parsing - analyse incompl√®te',
                'critical_issues': ['Erreur lors de l\'analyse'],
                'key_opportunities': []
            }
        }
    
    async def _generate_recommendations_fallback(self, scores: Dict) -> list:
        """G√©n√®re des recommendations de base bas√©es sur les scores"""
        recommendations = []
        priority = 1
        
        # G√©n√©rer recs bas√©es sur les faibles scores
        for criterion, score in scores.items():
            if criterion == 'global_score':
                continue
                
            if score < 6.0:
                recommendations.append({
                    'title': f'Am√©liorer {criterion}',
                    'criterion': criterion,
                    'impact': 'high' if score < 4.0 else 'medium',
                    'effort': 'medium',
                    'priority': priority,
                    'description': f'Score actuel: {score}/10 - Optimisation requise',
                    'example': '√Ä d√©finir selon contexte'
                })
                priority += 1
        
        return recommendations


# Instance globale du service
analyzer_service = AnalyzerService()
